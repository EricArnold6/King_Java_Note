# 计算机概览

- 建议有计算机组成原理、计算机网络、操作系统、数据结构等基础！
- 主要以问答的方式引发深入的思考！

# 操作系统

- 什么是操作系统？
  - 如何管理计算机资源？
  - 硬件：计算资源、存储资源、设备资源
  - 软件：文件、应用程序
- 什么是系统调用？
  - 用户态？内核态？
  - 用户态如果要使用内核态的部分操作怎么办？系统调用！
  - 系统调用主要：内存、文件、设备、进程控制、进程通信
- 操作系统架构：
  - ![image-20211209090017879](readme.assets/image-20211209090017879.png)
- 什么是标准设备？（针对设备本身）
  - CPU使用设备的标准设备模型，是一种协议、规范，让CPU能够更好的调用设备
  - 标准设备：接口+内部
- 什么是标准协议？（针对CPU使用设备）
  - CPU使用设备的标准使用协议，是一种协议、规范
  - 一般是4步：轮询设备、IO读取、执行命令、轮询设备
- 存在的问题：
  - CPU如何调用设备？轮询=》浪费CPU
  - 如何降低管理设备的CPU开销？=》加一层！
- 什么是中断？（减少CPU开销）
  - CPU对系统发送某些事件的一种反应：CPU暂停并且保存当前程序，去执行另一个程序，执行完后再返回中断处继续执行
  - 此时：就可以将一些工作交给其他设备去完成，完成后给CPU发送中断请求即可，CPU无需轮询
  - 类别：根据是否是CPU引起的分为：外中断、内中断
  - 存在的问题：仍然需要CPU将磁盘缓存区的数据读取到内核空间的页缓存中！
- 什么是DMA？（优化数据存取）
  - DMA：Direct Memory Access：可以协调完成内存和设备之间的数据传递，无需CPU介入

## 进程线程

- 进程和线程？
  - 什么是进程？运行的程序，用来管理和调度计算机资源来执行相应的任务
  - 区别？
  - 状态？
    - 进程：new、ready、running、waiting、terminated
    - 线程：new、runnable、blocked、waiting、time_waiting、terminate
- 进程间如何通信？
  - 原理：专门开辟内核缓存区进行交换数据
  - 通信方式：管道、有名管道、信号、消息队列、信号量、共享内存、套接字
- 线程同步方式？
  - 什么是线程同步？一种解决资源共享的机制
  - 如何进行线程同步？
    - 互斥量(synchronized)、信号量(Semphers)、事件(通知+优先级)
- 进程调度？
  - 为什么需要进程调用？整个计算机资源要充分利用(CPU、memory)
  - 进程调度算法：
    - FCFS(First Come First Server)：先来先服务
    - SJF(Shortest Job First)：短作业优先
    - RR(Round Robin)：时间片轮询
    - PS(Priority Scheduling)：优先级调度
    - RRMF(Round Robin with Multiple Feedback)：多级反馈队列
    - HRRN(Highest Response Ratio Next)：高响应比优先

## 内存管理

- 内存如何分配、如何回收、虚拟地址？
- 内存管理方式：提高内存利用率、避免内存碎片
  - 块式管理(连续)、页式管理(离散)
  - 段式管理：代码段、数据段、堆栈段等
  - 段页式管理
- 局部性原理？虚拟内存的基石、虚拟地址存在的根本原因
  - 程序加载时加载部分就可以开始执行，其他部分可以留在外存等待执行时中断加载
  - 时间局部性
  - 空间局部性
- 虚拟内存？
  - 内存管理的一种技术，定义的一个连续的虚拟地址空间，为每个进程提供一个一致私有的地址空间，独享内存的错觉
  - 原理：局部性原理=>主存可以看做硬盘的高速缓存
- 逻辑地址？物理地址？
- 虚拟地址？虚拟寻址？
  - 虚拟地址就是逻辑地址：使内存相互隔离、可以访问大于可用物理内存的缓冲区，便于管理
  - 虚拟寻址：如何将虚拟地址转换为实际的物理地址？内存管理单元(MMU)
- 虚拟空间越大？页表越大？
  - 如何解决：多级页表
- 虚拟地址转为物理地址时间消耗？
  - 越快越好！=>加一层缓存的思想
  - 快表(TLB)：页表的缓存，一种高速缓存存储器(Cache)
- 虚拟内存的具体实现？
  - 请求分页管理
  - 请求分段管理
  - 请求段页式管理
  - 为什么要加请求两个字？
    - 因为并不是一次性将整个代码数据加载到内存中，而是使用局部性原理，先加载一部分，那就意味着剩下的部分需要按需加载！所以要请求！
  - 此时就需要：
    - 缺页中断机制
    - 页面置换算法
- 页面置换算法？
  - OPT：最佳页面置换算法
  - FIFO：先进先出页面置换算法
  - LRU：最近最久未被使用页面置换算法
  - LFU：最少使用页面置换算法

## I/O

- 主要从数据**从外部读取到用户可用状态**理解分析，而不是从硬件角度理解
- 用户态如何获取可用数据？
  - 阶段一：内核态等待从外部读取数据
  - 阶段二：CPU将数据从内核态缓存空间拷贝到用户态缓存空间给用户使用
- IO模型？一种IO规范(协议)
  - 用户进程如何读取数据？什么时候读取数据？
  - 如何更好的合理利用CPU资源和进程资源？
- IO模型分类？
  - 阻塞IO模型：两阶段用户进程都等待
  - 非阻塞IO模型：阶段一轮询(要监听多个socker只能多线程)，阶段二等待
  - IO多路复用模型：阶段一系统调用做轮询(可用监听多个socket)，阶段二等待
  - 信号驱动IO模型：阶段一等别人通知，阶段二等待
  - 异步IO模型：阶段一，阶段二都无需等待，内核全部完成后直接通知用户态操作即可
- 直接IO？非直接IO？
  - 直接IO：不经过页缓存，直接从文件系统读取磁盘数据
  - 非直接IO：从内核页缓存中读取数据
- 缓冲IO？非缓冲IO？再加一层
  - 缓冲IO：使用标准库的缓存实现文件数据的加速访问，减少系统调用
  - 非缓冲IO：直接使用系统调用访问文件数据，频繁的系统调用

## 数据存取-零拷贝

- 传统文件IO：**四次上下文切换，四次数据拷贝**
  - 拷贝：DMA：磁盘数据到内核缓存区
  - 拷贝：CPU：内核缓冲区到用户态缓冲区
  - 拷贝：CPU：用户态缓冲区到内核Socket缓冲区
  - 拷贝：DMA：内核Socket缓冲区到协议栈(网卡)
- mmap()：系统调用：使用指针完成IO的存在，将文件的一段数据映射到内存中；**四次上下文切换，三次数据拷贝**
  - 拷贝：DMA：磁盘数据到内核缓存区
  - 拷贝：通过mmap()的方式实现数据映射，无需CPU介入
  - 拷贝：CPU：用户态缓冲区到内核Socket缓冲区
  - 拷贝：DMA：内核Socket缓冲区到协议栈
- sendfile()：系统调用：直接从内核缓冲区将数据拷贝到socket缓冲区；**两次上下文切换，三次数据拷贝**
  - 拷贝：DMA：磁盘数据到内核缓存区
  - 拷贝：CPU：内核缓冲区到内核Socket缓冲区
  - 拷贝：DMA：内核Socket缓冲区到协议栈
- 零拷贝：
  - 改进senfile()：直接从内核缓冲区到协议栈(网卡)；**两次上下文切换，两次数据拷贝**
  - 拷贝：DMA：磁盘数据到内核缓存区
  - 拷贝：DMA：内核缓冲区到协议栈

